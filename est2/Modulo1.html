<!doctype html>
<html lang="pt">

	<head>
		<meta charset="utf-8">

		<title>Estatística para Data Science II</title>

		<meta name="author" content="Fernando Antonio Marques Filho">

		<meta name="apple-mobile-web-app-capable" content="yes">
		<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">

		<link rel="stylesheet" href="../css/reveal.css">
		<link rel="stylesheet" href="../css/misc.css">
		<link rel="stylesheet" href="../css/theme/sky.css" id="theme">

		<!-- Code syntax highlighting -->
		<link rel="stylesheet" href="../lib/css/zenburn.css">
		<style>
			img {
				border : 0px !important;
			}
		</style>
		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? '../css/print/pdf.css' : '../css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>

		<!--[if lt IE 9]>
		<script src="lib/js/html5shiv.js"></script>
		<![endif]-->
	</head>
	<body>
		<div class="reveal">
			<!-- Any section element inside of this container is displayed as a slide -->
			<div class="slides">
				<section>
					<h3>Regressão e Predição</h3>					<p>
						<small>Created by Fernando Marques </small>
					</p>
		</section>
		<section data-markdown>
			- Um dos objetivos em estatística é responder a pergunta de se a variável X está relacionada a Y, qual a relação
			e se podemos prever Y
			- A estatística e ciência de dados possuem grandes laços no campo de predição, qual o valor do alvo levando em conta as variáveis preditoras
			- Outra parte importante é a detecção de anomalias
			- A regressão linear simples modela a relação de uma variável X com outra Y. Outra forma que vimos de relacionar variáveis é a correlação.
			- Correlação indica a forma de relacionamento e regressão quantifica a natureza do relacionamento
		</section>
		<section data-markdown>
			## Regressão linear simples
			- Exemplo, anos exposto a poeira de algodão vs. perf (peak expiratory flow rate)
			- `ggplot(LungDisease, aes(y=PEFR,x=Exposure)) + geom_point()`
			- `cor(LungDisease$Exposure, LungDisease$PEFR)`
			- `model &lt;- lm(PEFR ~ Exposure, data= LungDisease)`
			- `model &lt;- lm(PEFR ~ Exposure, data= LungDisease)`
			- Coeficientes e Intercept
			- `ggplot(data=LungDisease, aes(y=PEFR, x= Exposure)) + geom_point() + geom_abline(slope = model$coefficients[2], intercept = model$coefficients[1])`
			- ` + geom_smooth` 
		</section>
		<section data-markdown="">
			## Regressão linear simples
			- Então a regressão linear tem a fórmula
			\begin{aligned}
			Y = b_0 + b_1X
			\end{aligned}
			ou
			\begin{aligned}
			PEFR = b0 + b_1Exposure
			\end{aligned}
			- b0 pode ser interpretado como o valor para nenhuma exposição
			- b1 seria para cada ano, em quanto cai o valor de PEFR
		</section>
		<section data-markdown>
			## Valores Ajustados e Resíduos
			- Como visto, os dados não cabem todos na linha a linha de regressão seria algo como
			\begin{aligned}
			Y = b_0 + b_1X + e_i
			\end{aligned}
			- Valores ajustados, também conhecido como valores previstos podem ser denotados por 
			\begin{aligned}
			\hat{Y} = \hat{b}_0 + \hat{b}_1X
			\end{aligned}
			- o ^ indica que os coeficientes são estimativas
			- O resíduo é calculado por 
			\begin{aligned}
			\hat{e}_i = Y_i - \hat{Y}_i
			\end{aligned}
		</section>
		<section data-markdown="">
			## Quadrados mínimos
			- Quão bom é o modelo para o nosso dado?
			- Quando a relação é clara, conseguimos ver a linha formada
			- Na prática, a linha de regressão é a linha que miniminiza a soma dos quadrados dos resíduos (RSS - residual sum of squares)
			\begin{aligned}
			RSS = \sum{ (Y_i - \hat{Y}_i)^2}
			\end{aligned}
			- É computacionalmente eficiente
			- Não é robusto
		</section>
		<section data-markdown="">
			## Predição e Explicação
			- Históricamente o uso de regressão é mais comum para tentar a relação entre as variáveis
			- Qual a relação entre consumo e GDP?
			- Com o _big data_ as regressões são usadas para prever novos dados
			- Só lembrando, que isso não garante nenhuma conclusão de causa
		</section>
		<section data-markdown="">
			- A equação de regressão mostra a relação entre uma variável dependente Y e a variável preditora ou independente X como uma linha
			- O modelo de predição retorna valores ajustados e resíduos
			- Normalmente são feitos usando o método de menor quadrado
			- Pode ser usado para explicação e para predição
		</section>
		<section data-markdown="">
			## Regressão Linear Múltipla
			- Quando temos multiplos preditores, a equação pode ser estendida para acomodar todos eles
			\begin{aligned}
			Y = b_0 + b_1X_1 + b_2X_2 + ... + b_pX_p + e
			\end{aligned}
			- Ao invés de uma linha temos um modelo linear, a relação entre cada coeficiente e sua variável é linear
			- Todos os outros conceitos como quadrado mínimo, valores ajustados e resíduo também são considerados
		</section>
		<section data-markdown="">
			## Regressão linear Múltipla
			- Vamos usar a regressão linear para descobrir qual seria o preço de uma casa baseado em alguns parâmetros
			- `head(house[, c("AdjSalePrice", "SqFtTotLiving", "SqFtLot", "Bathrooms", "Bedrooms", "BldgGrade")])` 
			- `house_lm &lt;- lm(AdjSalePrice ~ SqFtTotLiving + SqFtLot + Bathrooms + Bedrooms + BldgGrade,  
			data=house, na.action=na.omit)`
			- na.omit ignora registros que tenham valores faltando
			- `house_lm` 
			- Adicionar um finished square aumenta o preço em $229

		</section>
		<section data-markdown="">
			## Avaliando o modelo
			- Do ponto de vista do data science a métrica de performance mais importante é o desvio padrão empírico ou 
			raiz quadrada do erro quadrático médio do inglês _root mean squared error_ ou RMSE
			\begin{aligned}
			RMSE = \sqrt{\frac{\sum{(y_i - \hat{y}_i)^2}}{n}}
			\end{aligned}

		</section>
		<section data-markdown="">
			## Avaliando o modelo
			- Também temos o RSE (residual standard error) com p preditores
			\begin{aligned}
			RSE = \sqrt{\frac{\sum{(y_i - \hat{y}_i)^2}}{n-p-1}}
			\end{aligned}
			- A única diferença é que o RSE leva em conta os graus de liberdade, para dados grandes a diferença entre os dois é pequena
			- `summary(house_lm)`
		</section>
		<section data-markdown="">
			## Avaliando o modelo
			- Outra métrica usada é o coeficiente de determinação ou R-squarred R²
			- Ela retorna valores entre 0 e 1 e mede a proporção de variação dos dados que são levados em conta no modelo
			\begin{aligned}
			R^2 = 1- \frac{\sum{(y_i - \hat{y}_i)^2}}{\sum{(y_i-\bar{y}_i)^2}}
			\end{aligned}
			- Mostra o quão bem o modelo é ajustado aos dados
			- Outras estatísticas são t-statistic e valor-p, O valor p quanto menor melhor, já o t quanto maior melhor
		</section>
		<section data-markdown="">
			## Validação Cruzada
			- As estatísticas vistas são todas 'in-sample', ou seja, são usadas nos mesmos dados que foram usados para treinar o modelo
			- O ideal é separar uma parte da base para treinar o modelo e uma outra parte para testar
			- Esse método não é novo mas só é possível com maiores quantidades de dados
		</section>
		<section data-markdown="">
			## Validação Cruzada 
			### k-fold cross validation
			1. Separar 1/k dos dados
			1. Treinar o modelo com o restante dos dados
			1. Testar e salvar o valor
			1. Restaurar os dados e separar mais 1/k
			1. Repetir passos 2 e 3
			1. Repetir até que todos os dados tenham sido usados
			1. Tirar a média ou combinar as métricas testadas
				- A divisão dos dados em uma parte de teste é chamada de fold
		</section>
		<section>
			<pre><code class="R">
#Randomly shuffle the data
yourData&lt;-yourData[sample(nrow(yourData)),]

#Create 10 equally size folds
folds &lt;- cut(seq(1,nrow(yourData)),breaks=10,labels=FALSE)

#Perform 10 fold cross validation
for(i in 1:10){
	#Segement your data by fold using the which() function 
	testIndexes &lt;- which(folds==i,arr.ind=TRUE)
	testData &lt;- yourData[testIndexes, ]
	trainData &lt;- yourData[-testIndexes, ]
	#Use the test and train data partitions however you desire...
}
			</code></pre>
		</section>
		<section>
			<pre><code class="R">
require(caret)
flds &lt;- createFolds(LungDisease$Exposure)
train &lt;- LungDisease [ -flds[[1]],]
test &lt;- LungDisease[ flds[[1]],]
			</code></pre>
		</section>
		<section data-markdown="">
			## Regressão passo a passo
			- Em muitos modelos, mais variáveis podem ser adicionadas como preditoras da regressão
			- Para prever o valor da casa, podemos adicionar o tamanho do porão ou ano que a casa foi construída
			- `house_full &lt;- lm(AdjSalePrice ~ SqFtTotLiving + SqFtLot + Bathrooms + Bedrooms + BldgGrade + PropertyType + NbrLivingUnits + 	SqFtFinBasement + YrBuilt + YrRenovated + NewConstruction, data=house, na.action=na.omit)`
		</section>
		<section data-markdown="">
			## Regressão passo a passo
			- Novas variáveis nem sempre significam melhores modelos!
			- Novas variáveis reduzem o RMSE e aumentam o R²
			- Por isso, Hirotugu Akaike criou uma métrica que penaliza o uso de novos termos
			\begin{aligned}
			AIC = 2P + n log(RSS/n)
			\end{aligned}
			- P é o número de variáveis no modelo e n o número de registros
		</section>
		<section data-markdown="">
			## Regressão passo a passo
			\begin{aligned}
			RSS = \sqrt{\sum{(y_i - \hat{y}_i)^2}}
			\end{aligned}
			- Existem outras métricas como AICc, BIC e Mallow Cp
			> Como encontrar um modelo que minimize o AIC?
			- É computacionalmente caro para problemas com muitas variáveis
			- Um outro método é adicionar e remover preditores até encontrar um modelo com AIC baixo
		</section>
		<section data-markdown="">
			## Regressão passo a passo
			`library(MASS)`

			`step &lt; stepAIC(house_full, direction="both")`
			- forward selection &rArr; Adiciona o preditor que aumenta mais R², para quando não for significante
			- backward selection &rArr; Começa com modelo completo e remove preditores que não são significantes
			- outros exemplos são regressões penalizadas como ridge e lasso, que penalizam modelos com muitos preditores
		</section>
		<section data-markdown="">
			## Regressão passo a passo
			- A regressão passo a passo é in-sample e pode sofrer de over fitting
			- Em geral, os riscos de over fitting são menores quando a regressão é Linear
			- Para modelos mais sofisticados é importante usar validação cruzada
		</section>
		<section data-markdown="">
			## Regressão ponderada
			- Quando observações possuem precisão diferente
			- A análise de dados é de forma agregada, de tal forma que a variável de peso codifica quantas observações originais cada linha nos dados agregados representa
			- Por exemplo, vendas antigas são menos relevantes que as mais recentes
		</section>
		<section>
			<pre><code class="R">
house$Year = year(house$DocumentDate)
house$Weight = house$Year - 2005
house_wt &lt;- lm(AdjSalePrice ~ SqFtTotLiving + SqFtLot + Bathrooms + 
					Bedrooms + BldgGrade,
				data=house, weight=Weight, na.action=na.omit)
round(cbind(house_lm=house_lm$coefficients, 
			house_wt=house_wt$coefficients), digits=3)
			</code></pre>
		</section>
		<section data-markdown="">
			- Regressão linear múltipla modela a relação da variável resposta e multiplos preditores
			- A métricas mais importantes são RMSE e R²
			- O erro padrão dos coeficientes pode ser usado para media a confiabilidade
			- Regressão passo a passo é uma forma de identificar quais variáveis devem ser incluídas
			- Regressão balanceada permite dar mais ou menos peso as variáveis
		</section>
		<section data-markdown="">
			## Predição usando regressão
			- Em data science o principal uso da regressão é para predição
			- Mas como historicamente a regressão é usada para explicar os dados, a maioria das ferramentas são para auxiliar
			na explicação
		</section>
		<section data-markdown="">
			## Extrapolação
			- O modelo de predição não deve ser usado para dados extrapolados
			- O modelo só é válido para valores de preditores que temos dados suficientes, e mesmo assim podemos ter problemas
			- Exemplo, qual seria o preço estimado de um terreno de 5000 pés quadrados mas vazio?
			- -521,900 + 5000 x -0.605 = -$522,202
			- Isso acontece pois em nenhum momento foi treinado lotes vazios!
		</section>
		<section data-markdown="">
			## Confiança e Intervalos de Predição
			- Muitas das estatísticas envolvem entender e medir a variabilidade
			- T-statistic e valor-p
			- Uma métrica mais útil é o intervalo de confiança que são intervalos de incerteza dos coeficientes e da predição
			- Os intervalos de confiança mais comuns são os feitos para os coeficientes da regressão
		</section>
		<section data-markdown="">
			## Intervalos de Confiança e Predição
			1. Considere cada linha como um único item e coloque todos em uma caixa
			1. Retire os item, registre e devolva
			1. Repita o passo 2 n vezes (bootstrap)
			1. Ajuste a regressão e salve os coeficientes estimados
			1. Repita 2-4 R vezes ( 1000?)
			1. Encontre os percentis 5% e 95% para um intervalo de confiança de 90%
		</section>
		<section data-markdown="">
			## Intervalos de Confiança e Predição
			- Mais importante que o intervalo de confiança dos coeficientes é o intervalo de confiança dos valores previstos
			- A incerteza na predição ocorre por
				1. Incerteza dos preditores relevantes e seus coeficientes
				1. Erro adicional dos pontos individuais
			- Mesmo que tendo certeza dos valores a equação de regressão, o valor real de um preditor irá variar
			- Casas com os mesmos preditores podem ter preços diferentes
		</section>
		<section data-markdown="">
			## Intervalos de Confiança e Predição
			1. Tire uma amostra de bootstrap
			1. Ajuste a regressão e preveja um novo valor
			1. Tire um resíduo da regressão original e some ao valor previsto, armazene
			1. Repita de 1 a 3 1000 vezes
			1. Encontre encontre os percentis 2.25% e 97.5%
			[Exemplo de Boostrap para Regressão, apontar o que tá errado no site...](https://data-flair.training/blogs/bootstrapping-in-r/)
		</section>
		<section data-markdown="">
			- Extrapolação pode causar erros
			- Intervalos de confiança mostram a incerteza dos coeficientes
			- Intervalos de predição quantificam erros de predições individuais
			- A maioria dos software produz intervalo de confiança e predição
		</section>
		<section data-markdown="">
			## Valores categóricos na Regressão 
			- A regressão exige que os valores sejam inteiros
			- O que fazer com as variáveis categóricas?
				- Exemplo de categoria: motivo de empréstimo
			- A forma mais comum é utilizar as variáveis dummy
		</section>
		<section data-markdown="">
			## Variáveis dummy
			- `head(house[,"PropertyType"])`
			- `levels(house[,"PropertyType"])`
			- Para usar essas variáveis temos que converter elas para variáveis binárias
			- `prop_type_dummies &lt;- model.matrix(~PropertyType -1, data=house)`
			- `head(prop_type_dummies)`
			- Esse tipo de divisão é chamado de _one hot encoder_ ou codificador quente
		</section>
		<section data-markdown="">
			## Variáveis dummy
			- Para regressão uma variável com P valores é representada com P-1 colunas já que na regressão tem o termo de interceptação
			- Com esse termo, tendo P-1, sabemos o valor para P
			- Por padrão R usa o primeiro fator como interceptação
			- `lm(AdjSalePrice ~ SqFtTotLiving + SqFtLot + Bathrooms + 
			Bedrooms +  BldgGrade + PropertyType, data=house)`
			- Single Family  vale 85000 a menos e Townhouse 150000 a menos se comparados a Multiplex
			- Existem outras formas de codificação como sum contrasts, polynomial e outras mas as mais usadas são reference e one hot encoder
		</section>
		<section data-markdown="">
			## Fatores com muitos leveis
			- Algumas variáveis podem gerar um grande número de dummies binários
			- No caso das casas, existem 82 zip codes
			- `table(house$ZipCode)`
			- Seriam 81 novos coeficientes, sendo que só tinhamos 5!
			- Alguns zip code tem apenas 1 venda, o que é problemático
			- Mas não podemos desconsiderar essa variável! _location location location_
			- Os primeiros 03 dígitos indicam regiam submetropolitana, mas 983 tem poucas vendas
		</section>
		<section>
<pre><code class="R">
library(dplyr)
zip_groups &lt- house %>%
mutate(resid = residuals(house_lm)) %>%
group_by(ZipCode) %>%
summarize(med_resid = median(resid),
			cnt = n()) %>%
# sort the zip codes by the median residual
arrange(med_resid) %>%
mutate(cum_cnt = cumsum(cnt),
		ZipGroup = factor(ntile(cum_cnt, 5)))
house &lt- house %>%
left_join(select(zip_groups, ZipCode, ZipGroup), by='ZipCode')
</code></pre>
		</section>
		<section data-markdown="">
			## Fatores com muitos leveis
			- O resíduo da média é calculado para cada zipcode e a função ntile separa os códigos em grupos de 5
			- O conceito de usar resíduos para ajudar no ajuste da regressão é fundamental no processo de modelagem
		</section>
		<section data-markdown="">
			## Categorias ordenadas
			- Algumas categorias podem ser ordenadas, assim, usar a condição de decodificação perderia informação
			- Uma nota pode ser boa, média, ruim ...
			- [Ordered Factors](https://www.dummies.com/programming/r/how-to-work-with-ordered-factors-in-r/)
		</section>
		<section data-markdown="">
			- Fatores podem ser convertidos em números para fazer a regressão
			- O método mais comum de codificar um fator é usando P-1 variáveis dummy
			- Um fator com muitos níveis pode ter que ser convertido
			- Alguns fatores são ordenados e podem ser representados por números
		</section>
		<section data-markdown="">
			> Em data science o uso mais importante de regressão é predizer alguma variável dependente. Ainda assim, podemos
			conhecer a equação e entender o relacionamento das variáveis preditoras e a previsão 
		</section>
		<section data-markdown="">
			## Preditores correlacionados
			- Nas regressões múltiplas os preditores costumam ser correlacionados
			- Se olharmos os coeficientes do step_lm veremos que o coeficiente de quarto é negativo! HOW!?!?!
			- Adicionar um quarto à casa reduz seu preço?????
			- Casas grandes tendem a ter mais quartos, e é o tamanho que eleva o preço da casa
			- Em duas casa de mesmo tamanho, a que tiver mais quartos terá quartos menores
			- Preditores correlacionados podem dificultar a interpretação do valor de cada coeficiente
			- As variáveis para quartos, tamanho da casa e número de banheiros estão correlacionadas
		</section>
		<section data-markdown="">
			## Preditores correlacionados
			- `update(step_lm, . ~ . -SqtToLiving - SqFtFinBasement - Bathrooms)`
			- A função update pode ser usada para adicionar ou remover variáveis de um modelo
			- Agora a variável Bedrooms é positiva, mas funciona como um proxy para SqtToLiving

		</section>
		<section data-markdown="">
			## Multicolinearidade
			- Um caso extremo de variáveis correlacionadas é a multicolinearidade , uma condição onde há redundância
			entre as variáveis preditoras
			- Multicolinearidade perfeita é quando uma variável preditora pode ser descrita como uma regressão linear das outras
			- Multicolinearidade pode acontecer quando:
				- Uma variável é incluída múltiplas vezes por erro
				- São usadas P dummies
				- Duas variáveis são quase perfeitamente correlacionadas
		</section>
		<section data-markdown="">
			## Multicolinearidade
			- Multicolinearidade deve ser tratada em regressões! Removendo as variáveis correlacionadas
			- Não é um problema em outros tipos de métodos como arvores, clustering ou vizinhos mais próximos
		</section>
		<section data-markdown="">
			## Variável de Confusão ou Confundimento
			- Com variáveis correlacionadas o problema é adicionar muitas variáveis com relação similar a previsão
			- No confundimento o problema é a omissão, alguma variável importante não foi adicionada na regressão
			- Se adicionarmos ZipGroup a regressão agora teremos Bathroom e SqFtLot positivos
			- O coeficiente do Zip também é alto, podendo adicionar até $340,000
			- [Explicação sobre Variável de Confusão](https://www.statisticshowto.datasciencecentral.com/experimental-design/confounding-variable/)
		</section>
		<section data-markdown="">
			## Interações e Efeito principal
			- Existe uma diferença entre efeitos principais ou variáveis independentes e a interação entre os efeitos
			- Uma suposição implícita quando fazemos regressão é que o preditor e a resposta são independentes de outros preditores
			- Nem sempre isso acontece...
		</section>
		<section data-markdown="">
			## Interações e Efeito principal
			- Vimos o efeito do ZipCode nos outros coeficientes
			- Sabemos que no setor imobiliário localização é tudo. Assim, uma casa grande em uma área nobre não terá o mesmo
			preço que uma casa na perifería 
			- Para incluir interação entre variáveis em R usamos o operador *
			- `lm(AdjSalePrice ~  SqFtTotLiving*ZipGroup + SqFtLot + Bathrooms + Bedrooms +	BldgGrade + PropertyType,  data=house, na.action=na.omit)`
		</section>
		<section data-markdown="">
			## Interações e Efeito principal
			- São criados relacionamentos entre SqFtTotLiving e Zip Group 
			- A diferença de aumentar um pé quadrado dos Zips mais baratos para o mais caro é de 2.9!
			- $118 vs $348
			- Pode ser difícil decidir quais termos devem ser incluídos no modelo para isso podemos
				- Conhecimento do negócio e intuição
				- Stepwise
				- Usar regressão penalizada [exemplos](http://www.sthda.com/english/articles/37-model-selection-essentials-in-r/153-penalized-regression-essentials-ridge-lasso-elastic-net/)
				- Usar modelos de árvores
		</section>
		<section data-markdown="">
			- Por causa da correlação entre preditores é importante tomar cuidado com regressões multivariadas
			- Multicolinearidade pode causar instabilidade na regressão
			- Um variável de confusão é um preditor importante que foi omitido do modelo e pode levar a relacionamentos errados
			- Um termo de interação entre duas variáveis é importante quando o relacionamento entre as variáveis é interdependente
		</section>
		<section data-markdown="">
			## Diagnóstico de Regressão 
			### Outliers, Parte II - _O Retorno_
			- Outliers são valores que se distanciam das outras observações
			- Assim como na localização e variabilidade, os outliers também devem ser tratados na regressão
			- Não existe uma teoria estatística para reparar outliers, existem algumas boas práticas como 1.5 IQR
			- Os resíduos padronizados são a forma de encontrar outliers na regressão
			- Resíduo padronizado pode ser interpretado como o números de erros padrão distante da regressão
		</section>
		<section >
<pre><code class="R">
house_98105 &lt;- house[house$ZipCode == 98105,]
lm_98105 &lt;- lm(AdjSalePrice ~ SqFtTotLiving + SqFtLot + Bathrooms + 
	Bedrooms + BldgGrade, data=house_98105)
sresid &lt;- rstandard(lm_98105)
idx &lt;- order(sresid, decreasing=FALSE)
sresid[idx[1]]
resid(lm_98105)[idx[1]]

house_98105[idx[1], c('AdjSalePrice', 'SqFtTotLiving', 'SqFtLot',
	'Bathrooms', 'Bedrooms', 'BldgGrade')]
</code></pre>
		</section>
		<section data-markdown="">
			## Outliers
			- Houve um erro na estimativa de $757,753!!!
			- A casa foi vendida por um preço muito menor do que valia
			- Outros casos para outliers são dados entrados de forma errada e erro de unidades
			- Para big data outliers podem não ser um problema 
			- Porém, outliers são centrais na detecção de anomalias como na detecção de fraudes
		</section>
	
			</div>
		</div>

		<script src="../lib/js/head.min.js"></script>
		<script src="../js/reveal.js"></script>
		<script src="../js/base.js"></script>

		<script>

			// Full list of configuration options available at:
			// https://github.com/hakimel/reveal.js#configuration
			Reveal.initialize({
				controls: true,
				progress: true,
				history: true,
				center: true,
				slideNumber: 'c/t',

				transition: 'slide', // none/fade/slide/convex/concave/zoom
				math: {
					// mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js',
					config: 'TeX-AMS_HTML-full',
					TeX: {
						Macros: {
							R: '\\mathbb{R}',
							set: [ '\\left\\{#1 \\; ; \\; #2\\right\\}', 2 ]
						}
					}
				},
				// Optional reveal.js plugins
				dependencies: [
          { src: '../lib/js/classList.js', condition: function() { return !document.body.classList; } },
					{ src: '../plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: '../plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: '../plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
					{ src: '../plugin/zoom-js/zoom.js', async: true },
					{ src: '../plugin/notes/notes.js', async: true },
					{ src: '../plugin/math/math.js', async: true }
				]
			});

		</script>

	</body>
</html>
