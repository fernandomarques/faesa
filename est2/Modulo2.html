<!doctype html>
<html lang="pt">

	<head>
		<meta charset="utf-8">

		<title>Estatística para Data Science II</title>

		<meta name="author" content="Fernando Antonio Marques Filho">

		<meta name="apple-mobile-web-app-capable" content="yes">
		<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">

		<link rel="stylesheet" href="../css/reveal.css">
		<link rel="stylesheet" href="../css/misc.css">
		<link rel="stylesheet" href="../css/theme/sky.css" id="theme">

		<!-- Code syntax highlighting -->
		<link rel="stylesheet" href="../lib/css/zenburn.css">
		<style>
			img {
				border : 0px !important;
			}
		</style>
		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? '../css/print/pdf.css' : '../css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>

		<!--[if lt IE 9]>
		<script src="lib/js/html5shiv.js"></script>
		<![endif]-->
	</head>
	<body>
		<div class="reveal">
			<!-- Any section element inside of this container is displayed as a slide -->
			<div class="slides">
				<section>
					<h3>Regressão e Predição</h3>					<p>
						<small>Created by Fernando Marques </small>
					</p>
		</section>
		<section data-markdown="">
			## Valores influentes
			- Um valor cuja a ausência muda a equação de regressão
			- Consideramos que o ponto tem uma alta influência na regressão
			- Esse valor não é necessáriamente um outliers
			- Além do resíduo padronizado também existe o _hat-value_ e a distância de Cook
			\begin{aligned}
			Valor Hat &lt; 2(P+1)/n 
			\end{aligned}
			\begin{aligned}
			Valor Cook &lt; \frac{4}{n-P-1}
			\end{aligned}
		</section>
		<section data-markdown="">
			![Grafico Valor Influente](img/Modulo1ValorInfluente.png)
		</section>
		<section>
<pre><code>
seed &lt;- 11
set.seed(seed)
x &lt;- rnorm(25)
y &lt;- -x/5 + rnorm(25)
x[1] &lt;- 8
y[1] &lt;- 8
plot(x, y, xlab='', ylab='', pch=16)
model &lt;- lm(y~x)
abline(a=model$coefficients[1], b=model$coefficients[2], col="blue", lwd=3)
model &lt;- lm(y[-1]~x[-1])
abline(a=model$coefficients[1], b=model$coefficients[2], col="red", lwd=3, lty=2)
		
</code></pre>
		</section>
		<section>
<pre><code>
std_resid &lt;- rstandard(lm_98105)
cooks_D &lt;- cooks.distance(lm_98105)
hat_values &lt;- hatvalues(lm_98105)
df &lt;- data.frame(hat_value=hat_values, std_resid = std_resid, cooks_D = cooks_D)
ggplot(data=df, aes(x=hat_value,y=std_resid,size=cooks_D)) + 
   geom_point(shape=1) + geom_hline(yintercept = 2.5, linetype = "dashed") + 
   geom_hline(yintercept = -2.5, linetype = "dashed")
</code></pre>
		</section>
		<section>
<pre><code class="R">
lm_98105_inf &lt- lm(AdjSalePrice ~ SqFtTotLiving + SqFtLot + 
	Bathrooms +  Bedrooms + BldgGrade,
	subset=cooks_D&lt.08, data=house_98105)

df &lt- data.frame(lm_98105$coefficients,
	lm_98105_inf$coefficients)
names(df) &lt- c('Original', 'Influential Removed')
ascii((df),
include.rownames=TRUE, include.colnames=TRUE, header=TRUE,
digits=rep(0, 3), align=c("l", "r", "r") ,
caption="Comparison of regression coefficients with the full data and with influential data removed")
</code></pre>
		</section>
		<section data-markdown="">
			## Valores influentes
			- Notem que os valores de Bathrooms mudam radicalmente!
			- Para dados com muitas observações é pouco provável que uma única observação tenha peso suficiente para
			influenciar a regressão
			- Para propósitos de encontrar anomalias, valores influentes são bastante úteis
		</section>
		<section data-markdown="">
			## Heterocedasticidade
			- Para a maioria dos casos o estimador de quadrados mínimos é uma das melhores opções
			- Inferências normais assumem que os resíduos são normalmente distribuídos, tem a mesma variância e são
			independentes
			- Isso é particularmente importante quando calculamos o intervalo de confiança para os valores previstos, já que é baseado nos resíduos
			- Heterodasticidade é a falta de uma variação no resíduo ao longo dos valores preditos
			- Indica que erros de predição são diferentes para amplitudes diferentes
		</section>
		<section>
			<pre><code class="R">
df &lt;- data.frame(
	resid = residuals(lm_98105),
	pred = predict(lm_98105))
ggplot(df, aes(pred, abs(resid))) +
	geom_point() +
	geom_smooth() 

ggplot() + geom_qq_line(aes(sample=std_resid)) + geom_qq(aes(sample=std_resid))
			</code></pre>
		</section>
		<section data-markdown="">
			## Resíduos parciais e não linearidade
			- Gráficos de resíduo parcial são uma forma de explicar a relação entre o preditor e o resultado
			- Também ajuda a detectar outliers
			- A ideia é isolar o relacionamento entre a variável preditora e a resposta, considerando todos os outros preditores
			- O resíduo parcial combina o valor previsto por uma variável e o resíduo da regressão como um todo
			\begin{aligned}
			Partial residual = residual + \hat{b}_iX_i
			\end{aligned}
		</section>
		<section>
<pre><code>
terms &lt;- predict(lm_98105, type='terms')
partial_resid &lt;- resid(lm_98105) + terms

df &lt;- data.frame(SqFtTotLiving = house_98105[, 'SqFtTotLiving'],
	Terms = terms[, 'SqFtTotLiving'],
	PartialResid = partial_resid[, 'SqFtTotLiving'])
ggplot(df, aes(SqFtTotLiving, PartialResid)) +
	geom_point(shape=1) + scale_shape(solid = FALSE) +
	geom_smooth(linetype=2) + 
	geom_line(aes(SqFtTotLiving, Terms))  
</code></pre>
		</section>
		<section data-markdown="">
			## Resíduos parciais e não linearidade
			- A regressão subestima o valor das casas a baixo de 1000 pés quadrados e superestima o preço das casas
			entre 2000 e 3000, existem poucos pontos acima de 4000 para tirar conclusão
			- A diferença faz sentido, adicionar 500ft² a uma casa pequena faz mais diferença que adicionar os mesmos
			500 ft² a uma casa grande
			- Esse tipo de comportamento sugere que o termo SqFtToLiving não seja linear!
		</section>
		<section data-markdown="">
			## Polinomial
			\begin{aligned}
			Y = b_0 + b_1X +b_2X^2 + e
			\end{aligned}
			- `lm(AdjSalePrice ~ poly(SqFtTotLiving, 2) + SqFtLot +	BldgGrade + Bathrooms +  Bedrooms, 	data=house_98105) `
		</section>
		<section>
	<pre><code>
lm_poly &lt;- lm(AdjSalePrice ~  poly(SqFtTotLiving, 2) + SqFtLot + 
	BldgGrade +  Bathrooms +  Bedrooms,
	data=house_98105)
terms &lt;- predict(lm_poly, type='terms')
partial_resid &lt;- resid(lm_poly) + terms

df &lt;- data.frame(SqFtTotLiving = house_98105[, 'SqFtTotLiving'],
			 Terms = terms[, 1],
			 PartialResid = partial_resid[, 1])
ggplot(df, aes(SqFtTotLiving, PartialResid)) +
	geom_point(shape=1) + scale_shape(solid = FALSE) +
	geom_smooth(linetype=2) + 
	geom_line(aes(SqFtTotLiving, Terms))+
	theme_bw()
	</code></pre>
		</section>
		<section data-markdown="">
			## Spline?
			- As regressões polinomiais só conseguem atingir uma certa quantidade de curvatura
			- Simplesmente aumentar a ordem do polinômio não é a melhor forma
			- O Spline permite interpolar entre dois valores fixos
			- A definição técnica de spline é uma série de polinômios contínuos
			- Os polinômios são conectados a uma série de pontos fixos chamados de nós
			- Contrário das outras regressões, os coeficientes são de difícil entendimento, sendo melhor ver o gráfico
		</section>
		<section data-markdown="">
			![Exemplo Spline Real](img\Modulo1Spline.jpg)
		</section>
		<section >
<pre><code>
library(splines)
knots &lt;- quantile(house_98105$SqFtTotLiving, p=c(.25, .5, .75))
lm_spline &lt;- lm(AdjSalePrice ~ bs(SqFtTotLiving, knots=knots, degree=3) +  SqFtLot +  
	Bathrooms + Bedrooms + BldgGrade,  data=house_98105)
terms1 &lt;- predict(lm_spline, type='terms')
partial_resid1 &lt;- resid(lm_spline) + terms

df1 &lt;- data.frame(SqFtTotLiving = house_98105[, 'SqFtTotLiving'],
	Terms = terms1[, 1],
	PartialResid = partial_resid1[, 1])
ggplot(df1, aes(SqFtTotLiving, PartialResid)) +
	geom_point(shape=1) + scale_shape(solid = FALSE) +
	geom_smooth(linetype=2) + 
	geom_line(aes(SqFtTotLiving, Terms))+
	theme_bw()
</code></pre>				
		</section>
		<section data-markdown="">
			## Modelo Aditivo Generalizado
			- Do Ingles _Generalized Additive Models_
			- Suponha que você suspeite que a relação entre a resposta de uma variável preditora é não linear
			- Polinômios podem não ser flexíveis o suficiente e splines requerem que você especifique os nós
			- GAM é uma técnica para automaticamente ajustar um spline a regressão
			- A biblioteca mgcv permite fazer isso usando o s
		</section>
		<section>
<pre><code>
lm_gam &lt;- gam(AdjSalePrice ~ s(SqFtTotLiving) + SqFtLot +  Bathrooms +  Bedrooms + BldgGrade, 
              data=house_98105)
terms &lt;- predict.gam(lm_gam, type='terms')
partial_resid &lt;- resid(lm_gam) + terms

df &lt;- data.frame(SqFtTotLiving = house_98105[, 'SqFtTotLiving'],
	Terms = terms[, 5], PartialResid = partial_resid[, 5])
ggplot(df, aes(SqFtTotLiving, PartialResid)) +
  geom_point(shape=1) + scale_shape(solid = FALSE) +
  geom_smooth(linetype=2) + 
  geom_line(aes(SqFtTotLiving, Terms))  +
  theme_bw()
</code></pre>
		</section>
		<section data-markdown="">
			- Em regressão outliers são valores com resíduo alto
			- Multicolinearidade pode causar instabilidade na equação de regressão
			- Uma variável de confusão é um preditor que não foi levado em consideração
			- Um termo de interação é necessário de uma variável depende do nível de outra
			- Polinômios podem acomodar relacionamentos não lineares
			- Splines são séries de polinômios juntados no nó
			- GAM automatiza o processo de escolher os nós do spline
		</section>
			</div>
		</div>

		<script src="../lib/js/head.min.js"></script>
		<script src="../js/reveal.js"></script>
		<script src="../js/base.js"></script>

		<script>

			// Full list of configuration options available at:
			// https://github.com/hakimel/reveal.js#configuration
			Reveal.initialize({
				controls: true,
				progress: true,
				history: true,
				center: true,
				slideNumber: 'c/t',

				transition: 'slide', // none/fade/slide/convex/concave/zoom
				math: {
					// mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js',
					config: 'TeX-AMS_HTML-full',
					TeX: {
						Macros: {
							R: '\\mathbb{R}',
							set: [ '\\left\\{#1 \\; ; \\; #2\\right\\}', 2 ]
						}
					}
				},
				// Optional reveal.js plugins
				dependencies: [
          { src: '../lib/js/classList.js', condition: function() { return !document.body.classList; } },
					{ src: '../plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: '../plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: '../plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
					{ src: '../plugin/zoom-js/zoom.js', async: true },
					{ src: '../plugin/notes/notes.js', async: true },
					{ src: '../plugin/math/math.js', async: true }
				]
			});

		</script>

	</body>
</html>
